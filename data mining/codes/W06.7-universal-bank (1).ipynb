{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (c) 2022 Tim C. Smith, All rights reserved\n",
    ">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gs999erazKxt",
    "tags": []
   },
   "source": [
    "# Universal Bank Promotional Campaign: A practical illustration of *model performance assessment using confusion matrices*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universal Bank has begun a program to encourage existing customers to borrow via a consumer loan program. \n",
    "\n",
    "The bank has tested a loan promotion on a random sample of 5000 customers. This test promotion resulted in 480 of the 5000 existing customers accepting the offer. \n",
    "\n",
    "The bank is intrigued by the success of this promotion. It has hired you to help them develop a model to identify which of its remaining customers may accept a similar promotion. \n",
    "\n",
    "They hired you to help them reduce the promotion costs and target the offer to only a subset of its customers that or more likely to accept the offer. They disclosed that the cost to promote this offer is \\\\$10 dollars per customer, and the profit from obtaining a loan customer is \\\\$100. They have an additional 50,000 customers that have not been contacted about the promotion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary business problem scoping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting your analysis, you jot down what the profit and loss (P&L) must have been from their marking trial. Since they targeted every customer, they only have FP and TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$-2,000.00\n"
     ]
    }
   ],
   "source": [
    "TP_profit = 100 - 10   # the sale profit minus the targeting cost\n",
    "TN_profit = 10 # they wouldn't take a loan, and we didn't spend the money targeting them\n",
    "FP_profit = -10   # no loan profit, just the targeting cost\n",
    "FN_profit = -100+10  # they would have taken the loan, but we didn't target them \n",
    "\n",
    "# in the null model there are only FP's and TP's because everyone is considered a possible customer\n",
    "original_profit = 480*TP_profit + (5000-480)*FP_profit\n",
    "print(f\"${original_profit:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this approach on the remaining 50000 customers would not be a good business decision, as it would result in a loss of..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$-20,000.00\n"
     ]
    }
   ],
   "source": [
    "print(f\"${original_profit*50000/5000:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this initial analysis, it's clear that the bank cannot continue this promotion unless they have a model to help them identify the best potential customers. The best model possible would be 100% accurate. Universal Bank's initial test resulted in 480 or 5000 customers choosing to take the offer. The rate 480/5000 is, therefore, the expected rate of customers that take the request, and thus the expected profit result from a perfectly accurate model would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$884,000.00\n"
     ]
    }
   ],
   "source": [
    "print(f\"${(480*TP_profit+(5000-480)*TN_profit)*10:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Universal Bank is making the right decision in bringing you in to help them. You're probably now thinking you should renegotiate your constulting fee :)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load, Explore and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "3   4   35           9     100     94112       1    2.7          2         0   \n",
       "4   5   35           8      45     91330       4    1.0          2         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  \n",
       "3              0                   0           0       0           0  \n",
       "4              0                   0           0       0           1  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data direct from GitHub\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/prof-tcsmith/data/master/UniversalBank.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check column names, and for convenience, remove whitespaces..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Age', 'Experience', 'Income', 'ZIP Code', 'Family', 'CCAvg',\n",
       "       'Education', 'Mortgage', 'Personal Loan', 'Securities Account',\n",
       "       'CD Account', 'Online', 'CreditCard'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'AGE', 'EXPERIENCE', 'INCOME', 'ZIP_CODE', 'FAMILY', 'CCAVG',\n",
       "       'EDUCATION', 'MORTGAGE', 'PERSONAL_LOAN', 'SECURITIES_ACCOUNT',\n",
       "       'CD_ACCOUNT', 'ONLINE', 'CREDITCARD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = [s.strip().upper().replace(' ', '_') for s in df.columns] \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide that a couple of variables aren't predictors; therefore we drop them and then check if there are any missing values in the remaining variables..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE                   0\n",
       "EXPERIENCE            0\n",
       "INCOME                0\n",
       "FAMILY                0\n",
       "CCAVG                 0\n",
       "EDUCATION             0\n",
       "MORTGAGE              0\n",
       "PERSONAL_LOAN         0\n",
       "SECURITIES_ACCOUNT    0\n",
       "CD_ACCOUNT            0\n",
       "ONLINE                0\n",
       "CREDITCARD            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop ID, and Zip Code as predictors\n",
    "df = df.drop(columns=['ID', 'ZIP_CODE'])\n",
    "\n",
    "# check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the variable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE                     int64\n",
       "EXPERIENCE              int64\n",
       "INCOME                  int64\n",
       "FAMILY                  int64\n",
       "CCAVG                 float64\n",
       "EDUCATION               int64\n",
       "MORTGAGE                int64\n",
       "PERSONAL_LOAN           int64\n",
       "SECURITIES_ACCOUNT      int64\n",
       "CD_ACCOUNT              int64\n",
       "ONLINE                  int64\n",
       "CREDITCARD              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.SECURITIES_ACCOUNT.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.CD_ACCOUNT.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ONLINE.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.CREDITCARD.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.PERSONAL_LOAN.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.EDUCATION.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(\n",
    "    df, \n",
    "    prefix_sep='_', \n",
    "    dummy_na=False, \n",
    "    drop_first=True, \n",
    "    columns=['EDUCATION'], \n",
    "    dtype='int8'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>EXPERIENCE</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>FAMILY</th>\n",
       "      <th>CCAVG</th>\n",
       "      <th>MORTGAGE</th>\n",
       "      <th>PERSONAL_LOAN</th>\n",
       "      <th>SECURITIES_ACCOUNT</th>\n",
       "      <th>CD_ACCOUNT</th>\n",
       "      <th>ONLINE</th>\n",
       "      <th>CREDITCARD</th>\n",
       "      <th>EDUCATION_2</th>\n",
       "      <th>EDUCATION_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.00000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>45.338400</td>\n",
       "      <td>20.104600</td>\n",
       "      <td>73.774200</td>\n",
       "      <td>2.396400</td>\n",
       "      <td>1.937938</td>\n",
       "      <td>56.498800</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.104400</td>\n",
       "      <td>0.06040</td>\n",
       "      <td>0.596800</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>0.280600</td>\n",
       "      <td>0.300200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.463166</td>\n",
       "      <td>11.467954</td>\n",
       "      <td>46.033729</td>\n",
       "      <td>1.147663</td>\n",
       "      <td>1.747659</td>\n",
       "      <td>101.713802</td>\n",
       "      <td>0.294621</td>\n",
       "      <td>0.305809</td>\n",
       "      <td>0.23825</td>\n",
       "      <td>0.490589</td>\n",
       "      <td>0.455637</td>\n",
       "      <td>0.449337</td>\n",
       "      <td>0.458391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AGE   EXPERIENCE       INCOME       FAMILY        CCAVG  \\\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
       "mean     45.338400    20.104600    73.774200     2.396400     1.937938   \n",
       "std      11.463166    11.467954    46.033729     1.147663     1.747659   \n",
       "min      23.000000    -3.000000     8.000000     1.000000     0.000000   \n",
       "25%      35.000000    10.000000    39.000000     1.000000     0.700000   \n",
       "50%      45.000000    20.000000    64.000000     2.000000     1.500000   \n",
       "75%      55.000000    30.000000    98.000000     3.000000     2.500000   \n",
       "max      67.000000    43.000000   224.000000     4.000000    10.000000   \n",
       "\n",
       "          MORTGAGE  PERSONAL_LOAN  SECURITIES_ACCOUNT  CD_ACCOUNT  \\\n",
       "count  5000.000000    5000.000000         5000.000000  5000.00000   \n",
       "mean     56.498800       0.096000            0.104400     0.06040   \n",
       "std     101.713802       0.294621            0.305809     0.23825   \n",
       "min       0.000000       0.000000            0.000000     0.00000   \n",
       "25%       0.000000       0.000000            0.000000     0.00000   \n",
       "50%       0.000000       0.000000            0.000000     0.00000   \n",
       "75%     101.000000       0.000000            0.000000     0.00000   \n",
       "max     635.000000       1.000000            1.000000     1.00000   \n",
       "\n",
       "            ONLINE   CREDITCARD  EDUCATION_2  EDUCATION_3  \n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  \n",
       "mean      0.596800     0.294000     0.280600     0.300200  \n",
       "std       0.490589     0.455637     0.449337     0.458391  \n",
       "min       0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000  \n",
       "50%       1.000000     0.000000     0.000000     0.000000  \n",
       "75%       1.000000     1.000000     1.000000     1.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split and Normalize Data\n",
    "\n",
    "K-nn models are sensitive to differences in scale; therefore, we should begin by eliminating any differences in scale between the predictors/features. To accomplish this, we will standardize the values of each variable.\n",
    "\n",
    "We will use the popular sklearn library's 'standard scaler' to accomplish this. This library contains many of the common functions we require when conducting analytics. The standard scaler function will standardize our variables. To achieve this, we will first need to train the scaler on the training data and then apply this trained scaler to standardize both the training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing \n",
    "\n",
    "features = df.drop(columns=['PERSONAL_LOAN'])\n",
    "target = df['PERSONAL_LOAN']\n",
    "\n",
    "# split the data into validation and training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=1)\n",
    "\n",
    "# create a standard scaler and fit it to the training set of predictors\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform the predictors of training and validation sets\n",
    "X_train = scaler.transform(X_train) \n",
    "X_test = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "> * https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now explore the results of the standardization (NOTE: The returned object from a scaler transform is a numpy array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train a K-NN model\n",
    "\n",
    "You've heard that a good starting point in determining a k value is to try the square root of the total observations. Since there are 5000 observations, following this rule of thumb, we would select a k value of 70  (but it's best to choose an odd number so that we will use k=71).\n",
    "\n",
    "> If k is an even number, there is a possibility that an observation could have the same number of nearest neighbors being one class (they took the loan) as the number being another (did not take the loan). In the cases of a tie, the SKLearn implementation of k-nn will select the first found. Though the chances of this happening are low, it's better to avoid this by choosing an odd number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2764</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4767</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3814</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3922</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4054</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3903</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual  predicted\n",
       "2764       0          0\n",
       "4767       0          0\n",
       "3814       0          0\n",
       "3499       0          0\n",
       "2735       0          0\n",
       "3922       0          0\n",
       "2701       0          0\n",
       "1179       0          0\n",
       "932        0          0\n",
       "792        0          0\n",
       "1852       0          0\n",
       "1185       0          0\n",
       "1724       0          0\n",
       "4080       0          0\n",
       "3823       0          0\n",
       "4054       0          0\n",
       "2721       1          0\n",
       "3903       0          0\n",
       "1865       0          0\n",
       "759        0          0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=71,  metric='euclidean') # user euclidean distance\n",
    "\n",
    "# We could choose other distance metrics; for a list of other metrics...\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.distance_metrics.html#sklearn.metrics.pairwise.distance_metrics\n",
    "# coverage of difference distance metrics is outside of this courses scope... but, you can experiment by changing the metric\n",
    "# for example...\n",
    "#knn = KNeighborsClassifier(n_neighbors=71,  metric='manhattan')\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "results = pd.DataFrame()\n",
    "results['actual'] = y_test\n",
    "results['predicted'] = model.predict(X_test)\n",
    "results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "> * https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "> * https://scikit-learn.org/stable/modules/generated/sklearn.metrics.DistanceMetric.html#sklearn.metrics.DistanceMetric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PERSONAL_LOAN\n",
       "0    4520\n",
       "1     480\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PERSONAL_LOAN'].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.096"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PERSONAL_LOAN'].value_counts()[1] / (df['PERSONAL_LOAN'].value_counts()[1] + df['PERSONAL_LOAN'].value_counts()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted\n",
       "0    1469\n",
       "1      31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['predicted'].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020666666666666667"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['predicted'].value_counts()[1] / (results['predicted'].value_counts()[1] + results['predicted'].value_counts()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that we know that the TP rate is 480/5000 = 9.% in the sample, but our predictions have a TP rate of 2.7%. This is a bit of a 'red flag' to indicate that the precision of our model may be poor - which is most likely due to the imbalance between classes in our training data (480 in one class and 4520 in the other). Such imbalances can be a problem with many machine learning algorithms, including k-nn. Addressing this problem is a topic for another class, but the influence of the unbalanced data can be partially mitigated by using a smaller k value. We will see this in practice when we cover hyper-parameter tuning in the next class.\n",
    "\n",
    "> For now, we will ignore this potential opportunity to improve our model and move ahead with our analysis to see if this model is sufficient to help Universal Bank generate profit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hnRpvv2znmO6"
   },
   "source": [
    "## Measure performance of model using confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "wdGfPJfEYlRV",
    "outputId": "2fe22ed5-6d97-40cf-88e0-09f8f8cee8f4"
   },
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(results['actual'], results['predicted'])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1350,    1],\n",
       "       [ 119,   30]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "5ulijKuInH4J"
   },
   "outputs": [],
   "source": [
    "TP = confusion[1, 1] # True Positives\n",
    "TN = confusion[0, 0] # True Negatives\n",
    "FP = confusion[0, 1] # False Positives\n",
    "FN = confusion[1, 0] # False Negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8RSxiWGnJj2"
   },
   "source": [
    "### Accuracy:\n",
    "\n",
    "How often was the model correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "FfO1nisznIiI",
    "outputId": "878d0f2f-3f3a-41c7-9b9e-d0f428fb950e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9200\n"
     ]
    }
   ],
   "source": [
    "classification_accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "print(f\"{classification_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZGZKw3bnMye"
   },
   "source": [
    "### Misclassification Rate:\n",
    "\n",
    "How often was the model incorrect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "1YLQMVIVnMC_",
    "outputId": "8bfe3f91-530d-421f-aeda-5a53febf6635"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0800\n"
     ]
    }
   ],
   "source": [
    "classification_error = (FP + FN) / (TP + TN + FP + FN)\n",
    "# this is the same as ...\n",
    "# classification_error = 1-classification_accuracy\n",
    "\n",
    "print(f\"{classification_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzKkssIbnPXd"
   },
   "source": [
    "### Precision: \n",
    "\n",
    "When a positive value is predicted, how often is the prediction correct?\n",
    "\n",
    "In other wordes: How \"precise\" is the classifier when predicting positive instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "DE2o7HIxnP7F",
    "outputId": "cc8b3fe4-0e6e-428a-9907-e46e8e7d007e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9677\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "print(f\"{precision:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjSqr2r2nQPm"
   },
   "source": [
    "### Recall (aka sensititivy):\n",
    "\n",
    "Ability of a classification model to identify all relevant instances. \n",
    "Also referred to as Sensitivity, Probability of Detection, True Positive Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "DT7oM6VtoVuq",
    "outputId": "974479f7-52d7-4550-a4a3-d3556fe03f81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2013\n"
     ]
    }
   ],
   "source": [
    "recall = TP / (TP + FN)\n",
    "print(f\"{recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hK9rHhz8nPk8"
   },
   "source": [
    "### F1 Score\n",
    "\n",
    "This is a measure that takes the harmonic mean of precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "cXVb-Q59ox_k",
    "outputId": "ee546904-3955-492b-b0aa-b13cf06aacf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333\n"
     ]
    }
   ],
   "source": [
    "f1_Score = (2 * precision * recall) / (precision + recall)\n",
    "print(f\"{f1_Score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As the analytics consultant, you know what all the above performance measures mean - but while presenting this information to the CEO, she became impatient and interrupted you to ask how profit and loss will be impacted if they choose to use this model over simply targeting everyone (you then take a note to yourself to place more focus on profit and loss when speaking with future CEO's)*\n",
    "\n",
    "Let's look at how we could address this question..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is our k-nn model a better model that the null (promote to all) model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Based on your initial business problem scoping, you calculated Universal Bank's expected profit from targeting the remaining 50,000 customers without the support of a model was \\\\$-20,000.00. \n",
    "\n",
    "Let's calculate how much our model improves things..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What would be the expected returns from not using a model?\n",
    "\n",
    "From the initial trial, 480 of the 5000 (9.6%) customers targeted took the loan, and 5000-480 (90.4%) didn't take the loan. Since the initial test was on a random selection of customers and did not use a model, then the expected percentage of the 50000 customer will also be 9.6% and 90.4%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expected total from from null model is $-20,000.00\n"
     ]
    }
   ],
   "source": [
    "print(f\"The expected total from from null model is ${0.096 * 50_000 * TP_profit + 0.904 * 50_000 * FP_profit:0,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What would the expected returns from using our model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the confusion matrix of the performance of the model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1350,    1],\n",
       "       [ 119,   30]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert these values into percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.00000000e-01 6.66666667e-04]\n",
      " [7.93333333e-02 2.00000000e-02]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_perc = confusion/(.3 * 5_000)  # since the confusion matrix is for the performance on the test data. Test set is .30% of 5000, or 1500. \n",
    "print(confusion_perc)\n",
    "confusion_perc.sum() # this should add to one, if not, something is wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do a scaler multiplication of the number of customers that will be targetted in the newly proposed campaign (50,000 customers). This will give us the number of expected customers in each of the categories in the confusion matrix (TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.50000000e+04, 3.33333333e+01],\n",
       "       [3.96666667e+03, 1.00000000e+03]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_result = confusion_perc * 50_000\n",
    "knn_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a p_and_l matrix (profit and loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10, -10],\n",
       "       [-90,  90]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_and_l = np.array([[TN_profit, FP_profit],[FN_profit, TP_profit]])\n",
    "p_and_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple our profit and loss matrix with our knn_result matrix to get profit and loss associated with each of the catgories (FP, TP, FN, TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.50000000e+05, -3.33333333e+02],\n",
       "       [-3.57000000e+05,  9.00000000e+04]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_result * p_and_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the total profit, we simply need to sum up all the p_and_l's for each category (TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$182,666.67\n"
     ]
    }
   ],
   "source": [
    "model_profit = (knn_result * p_and_l).sum()\n",
    "\n",
    "print(f\"${model_profit:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, using a k value of 71 is not a very good value for k. At a loss of 236,000.00; this is much worse than the null model (where they simply don't use a model and target every customer) which was a loss of $20,000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing other values of k\n",
    "\n",
    "\n",
    "Let us explore the performance of our model.\n",
    "\n",
    "Notice that though accuracy looks quite good, recall is relatively poor. Since the cost of an FN is very high (loss of \\$100) relative to the cost of a false positive (a loss of \\$10), the distribution of the misclassified observations between FP and FN is significant. Any errors we must accept are much more advantageous if these are FP's. \n",
    "\n",
    "As we noted in the early stages of this evaluation (see note in \"Train a K-NN model\" section), our dataset is significantly unbalanced, with the number of customers not taking a loan nearly 10x higher than those that would take a loan. K-NN is particularly sensitive to this; in this case, the more significant proportion of observations where the customer did not take a loan makes it difficult for K-NN to identify the instances where they would take a loan. (since it is much more probable that a neighbor is a non-customer, and thus, the voting will skew towards selecting an observation as a non-customer). This problem gets worse as the value of k increases. \n",
    "\n",
    "Is all lost?\n",
    "\n",
    "We can make the model better. Due to the unbalanced nature of this dataset, we will likely find that the model will perform better with a lower value of k. \n",
    "\n",
    "Let us test this hypothesis by trying a range of k values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=1 model profit is $588,666.67\n",
      "For k=3 model profit is $532,666.67\n",
      "For k=5 model profit is $504,000.00\n",
      "For k=7 model profit is $482,000.00\n",
      "For k=9 model profit is $452,666.67\n",
      "For k=11 model profit is $404,666.67\n",
      "For k=13 model profit is $368,000.00\n",
      "For k=15 model profit is $350,000.00\n",
      "For k=17 model profit is $356,000.00\n",
      "For k=19 model profit is $362,000.00\n",
      "For k=21 model profit is $331,333.33\n",
      "For k=23 model profit is $331,333.33\n",
      "For k=25 model profit is $307,333.33\n",
      "For k=27 model profit is $301,333.33\n",
      "For k=29 model profit is $296,000.00\n",
      "For k=31 model profit is $290,666.67\n",
      "For k=33 model profit is $290,666.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=35 model profit is $272,666.67\n",
      "For k=37 model profit is $260,666.67\n",
      "For k=39 model profit is $260,666.67\n",
      "For k=41 model profit is $266,666.67\n",
      "For k=43 model profit is $260,666.67\n",
      "For k=45 model profit is $248,666.67\n",
      "For k=47 model profit is $248,666.67\n",
      "For k=49 model profit is $242,666.67\n",
      "For k=51 model profit is $242,666.67\n",
      "For k=53 model profit is $236,666.67\n",
      "For k=55 model profit is $218,666.67\n",
      "For k=57 model profit is $212,666.67\n",
      "For k=59 model profit is $200,666.67\n",
      "For k=61 model profit is $188,666.67\n",
      "For k=63 model profit is $176,666.67\n",
      "For k=65 model profit is $176,666.67\n",
      "For k=67 model profit is $176,666.67\n",
      "For k=69 model profit is $170,666.67\n",
      "For k=71 model profit is $182,666.67\n",
      "For k=73 model profit is $182,666.67\n"
     ]
    }
   ],
   "source": [
    "profits = []\n",
    "for i in range(1,141,2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i,  metric='euclidean')\n",
    "    knn.fit(X_train, y_train)\n",
    "    confusion = confusion_matrix(y_test, knn.predict(X_test))\n",
    "    confusion = confusion * 50_000 / confusion.sum()  # scaling this up to sample size of 50,000\n",
    "    TP = confusion[1, 1] \n",
    "    TN = confusion[0, 0] \n",
    "    FP = confusion[0, 1] \n",
    "    FN = confusion[1, 0]\n",
    "    profit_and_loss = np.array([[TN_profit, FP_profit],[FN_profit, TP_profit]])\n",
    "    model_profit = (confusion * profit_and_loss).sum()\n",
    "    profits.append(model_profit)\n",
    "    print(f\"For k={i} model profit is ${model_profit:,.2f}\")\n",
    "print(\"*\"*80)    \n",
    "print(f\"Max profit is {max(profits):,.2f}\")\n",
    "print(\"*\"*80)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Impact Summary\n",
    "\n",
    "Universal Bank's initial promotional campaign offered 5,000 existing customers a loan product. Of the 5,000 targeted, 480 accepted the offer. Since the cost of targeting a customer is \\$10, and the profit from getting a customer to take the loan is \\$100, this initial trial resulted in a loss of \\$2,000. If Universal Bank continued to use this 'null model' approach on the remaining 50,000 customers, this would result in a loss of \\$20,000. \n",
    "\n",
    "Using a k-nn model with k=1, the expected total profit is $582,000, but a k value this low will result in a model that is likely to overfit the training data and have a high variance on future predictions. \n",
    "\n",
    "Based on the expected performance of the proposed model, Universal Bank could proceed with implementing a profitable campaign. However, the data shows a significant imbalance, as more customers should have taken the offer. If we reduce the negative effect of the unbalanced data set, we can develop a better-performing model. (as a reminder, a 'perfect' model would produce a profit of $884,000.00; though we cannot expect a perfect model to be found, there is room for improvement).\n",
    "\n",
    "Also note that the best k value found is 1. This is not a good value for k, as it will result in a model that is likely to overfit and have a high variance on future predictions. Considering this, a much more stable prediction can be made with k=71 - which results in a profit of $182,666.67. We could argue that k should be lower, but we would need to consider the trade-off between variance and bias (something that will be discussed more later in the course). "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "jKZWz5SKzGNE",
    "QICirRwAt0AL"
   ],
   "include_colab_link": true,
   "name": "Class05-KNN_with_CONFUSION_MATRIX.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
